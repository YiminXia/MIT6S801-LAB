# Lab:locks

[toc]

在此次实验中，你会获得重新设计代码而带来并发性的经验。常见的现象是，锁的争用会导致多核机器并发性下降。为了改进并发性经常需要修改数据结构，修改锁的策略进而减少锁的争用。您将为xv6内存分配器和块缓存执行此操作。

>在写代码之前，你先把xv6 book中下面这些内容看完：
>
>* Chapter6：“Locking”与响应的代码。
>* Section3.5：“Code：Physical memory allocator"
>* Section8.1 到 8.3：“Overview","Buffer cache layer",和"Code:buffer cache。

```bash
$ git fetch
$ git checkout lock
$ make clean
```



## Memory allocator(moderate）

用户程序`user/kalloctest`强调xv6的memory allocator：三个进程增加或者缩小它们的地址空间，导致会经常调用`kalloc`跟`kfree`。`kalloc`跟`kfree`又都需要获取`kmem.lock`。`user/kalloctest`会打印 (as "#fetch-and-add")acquire函数中尝试获取lock的次数，kmem.lock与其他几种锁都有这种打印。acquire函数中的循环尝试获取锁的次数，可以粗糙的衡量锁竞争的烈度。在完成该实验之前，你运行`kalloctest`之后的输出看起来如下：

```bash
$ kalloctest
start test1
test1 results:
--- lock kmem/bcache stats
lock: kmem: #fetch-and-add 83375 #acquire() 433015
lock: bcache: #fetch-and-add 0 #acquire() 1260
--- top 5 contended locks:
lock: kmem: #fetch-and-add 83375 #acquire() 433015
lock: proc: #fetch-and-add 23737 #acquire() 130718
lock: virtio_disk: #fetch-and-add 11159 #acquire() 114
lock: proc: #fetch-and-add 5937 #acquire() 130786
lock: proc: #fetch-and-add 4080 #acquire() 130786
tot= 83375
test1 FAIL
```

Acquire为每个锁维护为该锁获取的调用计数，以及Acquire中的循环尝试设置锁但失败的次数。Kalloctest调用一个系统调用，使内核输出kmem和bcache锁（这是本实验的重点）和5个争用最多的锁的计数。如果存在锁争用，则acquire函数中循环迭代的次数将会很大。系统调用返回kmem和bcache锁的循环迭代次数的总和。

为了这个实验，你最好使用一个专门的空闲的机器而且得是多核的，如果你用的机器还敢别的事情，kalloctest的输出打印会相当离谱。你可以使用专门的Athena workstation，或者你自己的笔记本，不能使用dialup machine。

kalloctest程序引起lock contention的根因是kalloc函数中的的freelist被一个lock保护。要消除锁争用，必须重新设计memory allocator，以避免使用单个锁和列表。基本思想是为每个CPU维护一个freelist，每个freelist都有自己的锁。不同CPU上的allocations和frees可以并行运行，因为每个CPU将对不同的freelist进行操作。主要的挑战来自于当一个CPU的freelist耗尽了，但是别的CPU的freelist还有空余，此时一个CPU必须从其他CPU那里偷，这里可能会引起锁竞争，但是这种竞争基本上是罕见。

>你的任务是为每个CPU都实现一个freelist，当一个CPU的freelist耗尽了，从其他CPU偷。你必须给你的lock以kmem开头命名。也就是说，你得给你创建的每个lock都调用下initlock函数，还得将以kmem开头的锁名字当做入参传进入。运行`kalloctest`用户态程序看下你的实现是否减少了lock contention现象。
>
>为了检测是否可以完全分配完memory，你还得运行`usertests`跟`sbrkmuch`程序，你的输出打印得跟下面这张图差不多才行，要很明显看到kmem-locks的锁竞争已经大幅减少。确保`usertests`的所有测试用例都可以通过。`make grade`命令测试kalloctests是否通过。
>
>```
>$ kalloctest
>start test1
>test1 results:
>--- lock kmem/bcache stats
>lock: kmem: #fetch-and-add 0 #acquire() 42843
>lock: kmem: #fetch-and-add 0 #acquire() 198674
>lock: kmem: #fetch-and-add 0 #acquire() 191534
>lock: bcache: #fetch-and-add 0 #acquire() 1242
>--- top 5 contended locks:
>lock: proc: #fetch-and-add 43861 #acquire() 117281
>lock: virtio_disk: #fetch-and-add 5347 #acquire() 114
>lock: proc: #fetch-and-add 4856 #acquire() 117312
>lock: proc: #fetch-and-add 4168 #acquire() 117316
>lock: proc: #fetch-and-add 2797 #acquire() 117266
>tot= 0
>test1 OK
>start test2
>total free number of pages: 32499 (out of 32768)
>.....
>test2 OK
>$ usertests sbrkmuch
>usertests starting
>test sbrkmuch: OK
>ALL TESTS PASSED
>$ usertests
>...
>ALL TESTS PASSED
>$
>```

一些提示：

* 你可以使用常量NCPU，在kernel/param.h
* 让freerange将所有空闲内存分配给运行freerange的CPU。
* 函数cpuid返回当前的core编号，但是只有在中断关闭时调用它并使用它的结果才是安全的。您应该使用push_off（）和pop_off（）来关闭和打开中断。
* 请查看kernel/sprintf.c中的snprintf函数，了解字符串格式化的想法。不过，将所有锁命名为“kmem”是可以的。



## memory allocate 答案

<font color=red>核心思想：一把大锁，拆成小锁</font>

`kernel/param.h`

```c
#define NCPU 3 // maximum number of CPUs
```

`kernel/kalloc.c`

```c
typedef struct {
  struct spinlock lock;
  struct run *freelist;
} kmem;

kmem cpuskmem[NCPU];

void
kinit()
{
  // initlock(&kmem.lock, "kmem");
  for(int i = 0; i < NCPU; i++){
    cpuskmem[i].freelist = 0;
    initlock(&cpuskmem[i].lock, "kmem");
  }
  freerange(end, (void*)PHYSTOP);
}

void
freerange(void *pa_start, void *pa_end)
{
  char *p;
  p = (char*)PGROUNDUP((uint64)pa_start);
  int counter = 0;
  for(; p + PGSIZE <= (char*)pa_end; p += PGSIZE){
    memset(p, 1, PGSIZE);
    struct run* r = (struct run*)p;
    int index = counter % NCPU;
    r->next = cpuskmem[index].freelist;
    cpuskmem[index].freelist = r;
  }
}

// Free the page of physical memory pointed at by v,
// which normally should have been returned by a
// call to kalloc().  (The exception is when
// initializing the allocator; see kinit above.)
void
kfree(void *pa)
{
  struct run *r;
  if(((uint64)pa % PGSIZE) != 0 || (char*)pa < end || (uint64)pa >= PHYSTOP)
    panic("kfree");
  // Fill with junk to catch dangling refs.
  memset(pa, 1, PGSIZE);

  r = (struct run*)pa;

  push_off();
  int hart = cpuid();
  pop_off();

  acquire(&cpuskmem[hart].lock);
  r->next = cpuskmem[hart].freelist;
  cpuskmem[hart].freelist = r;
  release(&cpuskmem[hart].lock);
}


// Allocate one 4096-byte page of physical memory.
// Returns a pointer that the kernel can use.
// Returns 0 if the memory cannot be allocated.
void *
kalloc(void)
{
  // struct run *r;

  // acquire(&kmem.lock);
  // r = kmem.freelist;
  // if(r)
  //   kmem.freelist = r->next;
  // release(&kmem.lock);

  // if(r)
  //   memset((char*)r, 5, PGSIZE); // fill with junk
  // return (void*)r;

  struct run *r;

  push_off();
  int hart = cpuid();
  pop_off();

  acquire(&cpuskmem[hart].lock);
  r = cpuskmem[hart].freelist;
  if(r)
    cpuskmem[hart].freelist = r->next;
  release(&cpuskmem[hart].lock);

  if(r){
    memset((char*)r, 5, PGSIZE);
    return (void*)r;
  } else {
    for(int i = 0; i < NCPU; i++){
      acquire(&cpuskmem[i].lock);
      r = cpuskmem[i].freelist;
      if(r)
        cpuskmem[i].freelist = r->next;
      release(&cpuskmem[i].lock);
      if(r){
        memset((char*)r, 5, PGSIZE);
        return (void*)r;
      }
    }
  }
  return (void*)r;
}
```

step0:定义一共使用`#define NCPU 3 // maximum number of CPUs`3个CPU。

step1:定义结构体`kmem`内含`spinlock`自旋锁，然后定义一个`kmem cpuskmem[NCPU];`数组，每个CPU一个。

step2:`kinit()`中初始锁，然后调用`freerange`函数,平均将物理内存分给3个CPU。

step3：kfree，该CPU调用kfree函数释放物理内存，

* 先acquire该CPU的kmem对应的自旋锁，然后将page加入到该CPU对应的freelist，然后release该CPU的kmem对应的自旋锁。

step4:kalloc函数，该CPU调用kalloc函数分配物理内存，

* 先acquire该CPU的kmem对应的自旋锁，然后遍历该CPU对应的freelist，有空闲page就返回，没有空闲page，都release该CPU的kmem对应的自旋锁。
* 如果该CPU对应的freelist没有空闲的page，则需要从其他CPU对应的freelist去借page，此时先acquire其他CPU的kmem对应的spinlock，然后返回page，最后释放其他CPU的kmem对应spinlock。



## buffer cache (hard)

本作业的这一部分与前半部分相互独立；无论您是否完成了前半部分，都可以着手进行这一部分（并通过测试）。

如果多个进程密集的使用文件系统，它们可能会对bcache.lock产生争用，这个锁在kernel/bio.c是对disk block cache进行保护。bcachetest创建了很多进程然后频繁的访问各种不同的文件，目的是产生对bcache.lock产生争用；在你没有完成作业前，它的输出大约是下面这样：

```bash
$ bcachetest
start test0
test0 results:
--- lock kmem/bcache stats
lock: kmem: #fetch-and-add 0 #acquire() 33035
lock: bcache: #fetch-and-add 16142 #acquire() 65978
--- top 5 contended locks:
lock: virtio_disk: #fetch-and-add 162870 #acquire() 1188
lock: proc: #fetch-and-add 51936 #acquire() 73732
lock: bcache: #fetch-and-add 16142 #acquire() 65978
lock: uart: #fetch-and-add 7505 #acquire() 117
lock: proc: #fetch-and-add 6937 #acquire() 73420
tot= 16142
test0: FAIL
start test1
test1 OK
```

你的输出可能跟上面的略有不同，但是acquire函数对于bcache lock的loop iterations的数目会很大。如果你看下kernel/bio.c代码，你会看到bcache.lock保护的是cached block buffers的list，每个block buffer的引用计数（b->refcnt），以及cached blocks的标识（b->dev和b->blockno）。

>修改块缓存，以便在运行 bcachetest 时，使用acquire函数对bcache 中所有锁的循环迭代次数接近于零。理想情况下，块缓存中涉及的所有锁的计数总和应为零，但如果总和小于 500 也是可以接受的。修改 bget 和 brelse，使得对 bcache 中不同块的并发lookups和release不太可能在锁上发生冲突（例如，不必都等待 bcache.lock）。必须保持每个块在缓存中最多只有一份副本。完成之后，您的输出应类似于下面所示（尽管不完全相同）。确保 usertests 仍然通过。完成时，make grade 应通过所有测试。
>
>```bash
>$ bcachetest
>start test0
>test0 results:
>--- lock kmem/bcache stats
>lock: kmem: #fetch-and-add 0 #acquire() 32954
>lock: kmem: #fetch-and-add 0 #acquire() 75
>lock: kmem: #fetch-and-add 0 #acquire() 73
>lock: bcache: #fetch-and-add 0 #acquire() 85
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 4159
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 2118
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 4274
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 4326
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 6334
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 6321
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 6704
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 6696
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 7757
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 6199
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 4136
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 4136
>lock: bcache.bucket: #fetch-and-add 0 #acquire() 2123
>--- top 5 contended locks:
>lock: virtio_disk: #fetch-and-add 158235 #acquire() 1193
>lock: proc: #fetch-and-add 117563 #acquire() 3708493
>lock: proc: #fetch-and-add 65921 #acquire() 3710254
>lock: proc: #fetch-and-add 44090 #acquire() 3708607
>lock: proc: #fetch-and-add 43252 #acquire() 3708521
>tot= 128
>test0: OK
>start test1
>test1 OK
>$ usertests
>...
>ALL TESTS PASSED
>$
>
>
>
>
>
>$ bcachetest
>start test0
>test0 results:
>--- lock kmem/bcache stats
>lock: kmem: #fetch-and-add 0 #acquire() 264
>lock: kmem: #fetch-and-add 0 #acquire() 181
>lock: kmem: #fetch-and-add 0 #acquire() 124
>lock: bcache: #fetch-and-add 1538 #acquire() 32547
>--- top 5 contended locks:
>lock: virtio_disk: #fetch-and-add 16080553 #acquire() 2113
>lock: proc: #fetch-and-add 1154864 #acquire() 103565
>lock: proc: #fetch-and-add 862382 #acquire() 103518
>lock: proc: #fetch-and-add 844422 #acquire() 103517
>lock: proc: #fetch-and-add 722782 #acquire() 103518
>tot= 1538
>test0: FAIL
>start test1
>QEMU: Terminated
>
>```

请将您所有的锁都命名为以“bcache”开头的名称。也就是说，您应该为每个锁调用 initlock，并传入以“bcache”开头的名称。

减少块缓存中的争用比减少kalloc更棘手，因为bcache buffers实际上是在各个processes（以及cpu）之间共享的。对于kalloc，可以通过为每个CPU分配allocator来消除大多数争用；我们建议你查找cache中的block numbers通过hash table来实现，每个hash bucket都有一个lock。

在某些情况下，如果你的解决方案有锁冲突是可以的：

* 当两个进程并发地使用同一个block number时。bcachetest test0从不这样做。
* 当两个进程并发的miss in cache，并且需要找到一个未使用的块来替换时。Bcachetest test0从不这样做。
* 当两个进程并发地使用块时，无论你使用什么方案来划分blocks和locks，都存在冲突；例如，如果两个进程使用的blokcs的block numbers散列到哈希表中的同一槽。bcachetest test0可能会这样做，这取决于您的设计，但是您应该尝试调整方案的细节以避免冲突（例如，更改hash table的大小）。

bcachetest的test1使用了比缓冲区更多的不同块，并执行了许多文件系统代码路径。

下面是一些提示：

* 请阅读xv6书中关于块缓存的描述（第8.1-8.3节）。
* 使用固定数量的桶而不动态调整哈希表的大小是可以的。使用素数的桶（例如，13）来减少哈希冲突的可能性。
* 在哈希表中搜索buffer并在没有找到buffer时为该buffer分配条目必须是原子式的。
* 删除所有缓冲区的列表（bcache.head），使用它们最后一次使用的时间来代替时间戳缓冲区 (i.e., using ticks in kernel/trap.c)。通过这种修改，bget不需要获取bcache锁，并且bget可以根据时间戳选择最近最少使用的块。
* 在bget中序列化驱逐是可以的（即，当缓存中的查找失败时，bget选择一个缓冲区来重用的部分）。
* 在某些情况下，您的解决方案可能需要持有两个锁；例如，在清除期间，您可能需要持有bcache锁和每个桶的锁。确保避免死锁。
* 当替换一个块时，您可能会将一个结构体从一个桶移动到另一个桶，因为新块散列到另一个桶。您可能遇到一个棘手的情况：新块可能散列到与旧块相同的桶中。在这种情况下，请确保避免死锁。
* 一些调试提示：实现桶锁，但保留全局bcache。在对象的开始/结束处锁定获取/释放，以序列化代码。一旦您确定它是正确的，没有竞争条件，删除全局锁并处理并发问题。您还可以运行make cpu =1 qemu来使用一个核心进行测试。



## buffer cache答案

<font color=red>核心思想：一把大锁，拆成小锁</font>

`kernel/param.h`

```c
#define NBUCKT       13
#define NBUF         (NBUCKT*3)  // size of disk block cache
```





`kernel/buf.h`

```c
struct buf {
  int valid;   // has data been read from disk?
  int disk;    // does disk "own" buf?
  uint dev;
  uint blockno;
  struct sleeplock lock;
  uint refcnt;
  struct buf *prev; // LRU cache list
  struct buf *next;
  uchar data[BSIZE];
  uint ticks;
};
```





`kernel/bio.c`

```c
struct {
  struct spinlock lock;
  struct buf buf[NBUF];
  // Linked list of all buffers, through prev/next.
  // Sorted by how recently the buffer was used.
  // head.next is most recent, head.prev is least.
  // struct buf head; // dummy head node
} bcache;

struct {
  struct buf head;// dummy head node
  struct spinlock bucketlock; // lock of per bucket
} hashtable[NBUCKT];

void
binit(void)
{
  struct buf *b;
  initlock(&bcache.lock, "bcache");

  for(int i = 0; i < NBUCKT; i++){
    hashtable[i].head.prev = &(hashtable[i].head);
    hashtable[i].head.next = &(hashtable[i].head);
    initlock(&(hashtable[i].bucketlock), "bcache.bucket");
  }

  for(b = bcache.buf; b < bcache.buf+NBUF; b++){
    b->next = hashtable[0].head.next;
    b->prev = &(hashtable[0].head);
    initsleeplock(&b->lock, "buffer");
    hashtable[0].head.next->prev = b;
    hashtable[0].head.next = b;
  }
}

static int
hashcompute(uint dev, uint blockno){
  return blockno % NBUCKT;
}

// Look through buffer cache for block on device dev.
// If not found, allocate a buffer.
// In either case, return locked buffer.
static struct buf*
bget(uint dev, uint blockno)
{
  struct buf *b;

  int bucketIndex = hashcompute(dev, blockno);
  // printf("bucketIndex:%d\n",bucketIndex);
  acquire(&(hashtable[bucketIndex].bucketlock));
  // Is the block already cached?
  for(b = hashtable[bucketIndex].head.next; b != &hashtable[bucketIndex].head; b = b->next){
    if(b->dev == dev && b->blockno == blockno){
      b->refcnt++;
      release(&(hashtable[bucketIndex].bucketlock));
      acquiresleep(&b->lock);
      return b;
    }
  }

  // Not cached
  struct buf *tmp = 0;
  uint minticks = 0x8fffffff;
  // first select the curr bucket
  for(b = hashtable[bucketIndex].head.next; b != &(hashtable[bucketIndex].head); b = b->next){
    if(b->refcnt == 0 && b->ticks < minticks){
      tmp = b;
      minticks = b->ticks;
    }
  }
  if(tmp){
    goto find;
  }
  // release(&hashtable[bucketIndex].bucketlock);

  // select the whole array
  acquire(&bcache.lock);
refind:
  for(b = bcache.buf; b < bcache.buf+NBUF; b++){
    if(b->refcnt == 0 && b->ticks < minticks){
      tmp = b;
      minticks = b->ticks;
    }
  }

  if(tmp){
    // int index = hashcompute(tmp->dev, tmp->blockno);
    // acquire(&(hashtable[index].bucketlock));
    if(tmp->refcnt != 0)
      goto refind;
    tmp->next->prev = tmp->prev;
    tmp->prev->next = tmp->next;
    tmp->next = hashtable[bucketIndex].head.next;
    tmp->prev = &(hashtable[bucketIndex].head);
    hashtable[bucketIndex].head.next->prev = tmp;
    hashtable[bucketIndex].head.next = tmp;
    // release(&(hashtable[index].bucketlock));
    release(&bcache.lock);
    goto find;
  } else {
    goto refind;
  }

find:
  tmp->dev = dev;
  tmp->blockno = blockno;
  tmp->valid = 0;
  tmp->refcnt = 1;
  release(&(hashtable[bucketIndex].bucketlock));
  acquiresleep(&tmp->lock);
  return tmp;
}

// Release a locked buffer.
// Move to the head of the most-recently-used list.
void
brelse(struct buf *b)
{
  if(!holdingsleep(&b->lock))
    panic("brelse");

  releasesleep(&b->lock);

  int bucketIndex = hashcompute(b->dev, b->blockno);
  acquire(&(hashtable[bucketIndex].bucketlock));
  b->refcnt--;
  if (b->refcnt == 0) {
    // no one is waiting for it.
    // acquire(&bcache.lock);
    b->next->prev = b->prev;
    b->prev->next = b->next;
    b->next = hashtable[bucketIndex].head.next;
    b->prev = &(hashtable[bucketIndex].head);
    hashtable[bucketIndex].head.next->prev = b;
    hashtable[bucketIndex].head.next = b;
    // release(&bcache.lock);
  }
  b->ticks = ticks;
  release(&(hashtable[bucketIndex].bucketlock));
}

void
bpin(struct buf *b) {
  int bucketIndex = hashcompute(b->dev, b->blockno);
  acquire(&(hashtable[bucketIndex].bucketlock));
  b->refcnt++;
  release(&(hashtable[bucketIndex].bucketlock));
}

void
bunpin(struct buf *b) {
  int bucketIndex = hashcompute(b->dev, b->blockno);
  acquire(&(hashtable[bucketIndex].bucketlock));
  b->refcnt--;
  release(&(hashtable[bucketIndex].bucketlock));
}
```





实验2：xv6的buffer cache，就是disk在memory上的镜像，之前是一个LRU（Least Recently used）双向链表维护的，这个链表很巧妙，正向遍历（next方向）是最近刚使用的buffer，逆向（prev方向）遍历是最不常使用的buffer。

这就导致每次bget获取与brelse释放都会对bcache.lock产生争用。建议使用hash table与hash bucket提高并发性能，每个bucket都配一把锁。

本题的前置条件:

* 当两个进程并发地使用同一个block number时。bcachetest test0从不这样做。
* 当两个进程并发的miss in cache，并且需要找到一个未使用的块来替换时。Bcachetest test0从不这样做。
* 当两个进程并发地使用块时，无论你使用什么方案来划分blocks和locks，都存在冲突；例如，如果两个进程使用的blokcs的block numbers散列到哈希表中的同一槽。bcachetest test0可能会这样做，这取决于您的设计，但是您应该尝试调整方案的细节以避免冲突（例如，更改hash table的大小）。

导致你可以写出很多死锁的代码，但是依旧可以通过？

step1：`struct buf`中添加先字段ticks，用户记录最近一次brelease该buffer时候的ticks时间，我们通过该ticks的大小来判断buffer是否最近配置使用，ticks越大说明越刚才被使用过。

step2:生产一个hashtable[13]，表长为13，桶长为3；这个hashtable采用双向循环列表，所以head节点，使用dummy head，即是个假head部。真实节点是一个数组结构，是bcahe.buf[NBUF]

```c
struct {
  struct spinlock lock;
  struct buf buf[NBUF];
  // Linked list of all buffers, through prev/next.
  // Sorted by how recently the buffer was used.
  // head.next is most recent, head.prev is least.
  // struct buf head; // dummy head node
} bcache;
```



step3：`binit(void)`函数初始化，两个锁`initlock(&bcache.lock, "bcache");`与`initlock(&(hashtable[i].bucketlock), "bcache.bucket");`，前者是数组锁，后者是桶锁。



step4：`bget`函数，

* 通过`int bucketIndex = hashcompute(dev, blockno);`计算出桶的index；acquire桶锁<font color=red>lock1</font>，查找buffer，找到之后释放桶锁<font color=red>lock1</font>。
* 如果没有找到即not cached，那么在当前`hashtable[bucketIndex]`桶内继续查找，找出空闲(rnfcnt==0)且ticks最小的buf，释放桶锁<font color=red>lock1</font>。
* 如果还是没有，则获取数组锁<font color=green>lock2</font>，遍历整个数组，找出空闲(rnfcnt==0)且ticks最小的buf，
* 获取该buf的``hashtable[index]`的锁<font color=blue>lock3</font>，将buf从桶中移除，释放该桶锁<font color=blue>lock3</font>。
* 然后添加到`hashtable[bucketIndex]`桶中。释放数组锁<font color=green>lock2</font>，
* 释放该桶锁<font color=red>lock1</font>。



step5：`brelse`函数，只acquire与release桶锁<font color=red>lock1</font>就可以了



step6：`bpin`函数与`bunpin`函数，只acquire与release桶锁就可以了



##  测试结果

```bash
xym@ubuntu:~/xv6-labs-2020$ make grade
make clean
......
make[1]: Leaving directory '/home/xym/xv6-labs-2020'
== Test running kalloctest ==
$ make qemu-gdb
(64.6s)
== Test   kalloctest: test1 ==
  kalloctest: test1: OK
== Test   kalloctest: test2 ==
  kalloctest: test2: OK
== Test kalloctest: sbrkmuch ==
$ make qemu-gdb
kalloctest: sbrkmuch: OK (8.3s)
== Test running bcachetest ==
$ make qemu-gdb
(31.6s)
== Test   bcachetest: test0 ==
  bcachetest: test0: OK
== Test   bcachetest: test1 ==
  bcachetest: test1: OK
== Test usertests ==
$ make qemu-gdb
usertests: OK (130.5s)
== Test time ==
time: FAIL
    Cannot read time.txt
Score: 69/70
make: *** [Makefile:317: grade] Error 1
xym@ubuntu:~/xv6-labs-2020$

```



实验1：xv6本来只有一个freelist共享数据结构，三个核心上的kalloc与kfree会对其产生锁争用。memory page的分配完全序列化了，降低了系统的性能。

改进策略是为每个CPU分配一个freelist，比如CPU0，CPU1，CPU2对应的分别为freelist0,freelist1,freelist2。



实验2：xv6的buffer cache，就是disk在memory上的镜像，之前是一个LRU（Least Recently used）双向链表维护的，这个链表很巧妙，正向遍历（next方向）是最近刚使用的buffer，逆向（prev方向）遍历是最不常使用的buffer。

这就导致每次bget获取与brelse释放都会对bcache.lock产生争用。建议使用hash table与hash bucket提高并发性能，每个bucket都配一把锁。

本题的前置条件，导致你可以写出很多死锁的代码，但是依旧可以通过？



