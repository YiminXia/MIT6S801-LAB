# Multithreading

[toc]

本实验将使你熟悉多线程。您将在用户级线程包中实现线程之间的切换，使用多个线程来加速程序，并实现屏障。

>在编写代码之前，您应该确保已经阅读了xv6丛书中的“Chapter7：scheduling”，并学习了相应的代码。

开始实验，切换到thread分支

```bash
$ git fetch
$ git checkout thread
$ make clean
```



## Uthread: switching between threads ([moderate](https://pdos.csail.mit.edu/6.S081/2020/labs/guidance.html))

在本练习中，您将为用户级线程系统设计上下文切换机制，然后实现它。首先，您的xv6有两个文件user/uthread.c和user/uthread_switch.S，并在Makefile中添加一条规则来构建一个uthread program。uthread.c包含了大部分用户级线程包，以及三个简单测试线程的代码。线程包缺少一些创建线程和在线程之间切换的代码。

>您的工作是提出一个计划来create threads和save/restore registers以在线程之间切换，并实现该计划。当你完成后，make grade应该表明你的解决方案通过uthread test。

完成后，在xv6上运行uthread时应该看到以下输出（这三个线程可能以不同的顺序启动）：

```bash
$ make qemu
...
$ uthread
thread_a started
thread_b started
thread_c started
thread_c 0
thread_a 0
thread_b 0
thread_c 1
thread_a 1
thread_b 1
...
thread_c 99
thread_a 99
thread_b 99
thread_c: exit after 100
thread_a: exit after 100
thread_b: exit after 100
thread_schedule: no runnable threads
$
```

这个输出来自三个测试线程，每个线程都有一个循环然后打印一行，然后出让CPU给其他线程。

但是，如果你没有context切换代码，你就看不到这种输出。

您需要将代码添加到`user/uthread.c`文件中的`thread_create()`函数和`thread_schedule()`函数，以及将代码添加到`user/uthread_switch.S`文件中的`thread_switch`。

* 一个目标是确保当`thread_schedule()`第一次运行给定线程时，线程在自己的堆栈上执行传递给`thread_create()`的函数。

* 另一个目标是确保`thread_switch`保存被切走的线程的寄存器，restores被切换到的线程的寄存器，并返回到后一个线程指令中它最后离开的位置。

您必须决定在何处save/restore寄存器；修改`struct thread`来保存寄存器是一个很好的计划。你需要在`thread_schedule()`中添加一个对`thread_switch`的调用；您可以向`thread_switch`传递任何需要的参数，但目的是从线程`t`切换到`next_thread`。

一些提示：

* `thread_switch` 只需要save/restore callee-save registers，为什么？

* 您可以在`user/uthread.asm`中看到`uthread`的汇编代码。它可能对调试很方便。

* 要测试你的代码，使用`riscv64-linux-gnu-gdb`对`thread_switch`进行单步测试可能会有所帮助。你可以这样开始

  ```bash
  (gdb) file user/_uthread
  Reading symbols from user/_uthread...
  (gdb) b uthread.c:60
  ```

  这将在`thread.c`的第60行设置一个断点。断点可能（也可能不）在您运行`uthread`之前被触发。怎么会这样呢？

  一旦您的xv6 shell运行，输入`uthread`，gdb将在第60行中断。现在你可以输入如下命令来检查`uthread`的状态：

  ```bash
  (gdb) p/x *next_thread
  ```

  使用“x”，你可以检查内存位置的内容：

  ```bash
  (gdb) x/x next_thread->stack
  ```

  你可以这样跳到thread_switch的开始：

  ```bash
  (gdb) b thread_switch
  (gdb) c
  ```

  您可以使用以下命令单步汇编指令：

  ```bash
  (gdb) si
  ```

  On-line documentation for gdb is [here](https://sourceware.org/gdb/current/onlinedocs/gdb/).

## uthread 答案

```c
xym@ubuntu:~/xv6-labs-2020$ git diff user/uthread.c
diff --git a/user/uthread.c b/user/uthread.c
index 8e46826..5278763 100644
--- a/user/uthread.c
+++ b/user/uthread.c
@@ -10,11 +10,28 @@
 #define STACK_SIZE  8192
 #define MAX_THREAD  4

+struct context{
+  uint64      ra;
+  uint64      sp;
+  // callee-saved
+  uint64      s0;
+  uint64      s1;
+  uint64      s2;
+  uint64      s3;
+  uint64      s4;
+  uint64      s5;
+  uint64      s6;
+  uint64      s7;
+  uint64      s8;
+  uint64      s9;
+  uint64      s10;
+  uint64      s11;
+};

 struct thread {
   char       stack[STACK_SIZE]; /* the thread's stack */
   int        state;             /* FREE, RUNNING, RUNNABLE */
-
+  struct     context context;
 };
 struct thread all_thread[MAX_THREAD];
 struct thread *current_thread;
@@ -63,6 +80,7 @@ thread_schedule(void)
      * Invoke thread_switch to switch from t to next_thread:
      * thread_switch(??, ??);
      */
+    thread_switch((uint64)(&t->context), (uint64)(&current_thread->context));
   } else
     next_thread = 0;
 }
@@ -77,6 +95,9 @@ thread_create(void (*func)())
   }
   t->state = RUNNABLE;
   // YOUR CODE HERE
+  // printf("t->state:%d\n", t->state);
+  t->context.sp = (uint64)(t->stack) + STACK_SIZE;
+  t->context.ra = (uint64)(func);
 }

 void
```

解析：`all_thread`是个4个`struct thread`长度的数组，第一个元素是“无用”的，所以只有3个有效的`struct thread`结构体元素；看下`struct thread`的具体构成：

```c
struct context{
  uint64      ra;
  uint64      sp;
  // callee-saved
  uint64      s0;
  uint64      s1;
  uint64      s2;
  uint64      s3;
  uint64      s4;
  uint64      s5;
  uint64      s6;
  uint64      s7;
  uint64      s8;
  uint64      s9;
  uint64      s10;
  uint64      s11;
};

struct thread {
  char       stack[STACK_SIZE]; /* the thread's stack */
  int        state;             /* FREE, RUNNING, RUNNABLE */
  struct     context context;
};
```

其中`char stack[STACK_SIZE];`是用户线程执行的栈；`int state;`表示用户线程的状态；`struct context context`是我们新增的字段，用于save/restore当前用户线程的callee-saved registers的结构体；

我们在`thread_schedule`函数中个调用`thread_switch`函数，该函数由汇编代码实现。与kernel中的swtch.S的实现是一样的，如下：

```c
	.text

	/*
         * save the old thread's registers,
         * restore the new thread's registers.
         */

	.globl thread_switch
thread_switch:
	/* YOUR CODE HERE */
	sd ra, 0(a0)
	sd sp, 8(a0)
	sd s0, 16(a0)
	sd s1, 24(a0)
	sd s2, 32(a0)
	sd s3, 40(a0)
	sd s4, 48(a0)
	sd s5, 56(a0)
	sd s6, 64(a0)
	sd s7, 72(a0)
	sd s8, 80(a0)
	sd s9, 88(a0)
	sd s10, 96(a0)
	sd s11, 104(a0)

	ld ra, 0(a1)
	ld sp, 8(a1)
	ld s0, 16(a1)
	ld s1, 24(a1)
	ld s2, 32(a1)
	ld s3, 40(a1)
	ld s4, 48(a1)
	ld s5, 56(a1)
	ld s6, 64(a1)
	ld s7, 72(a1)
	ld s8, 80(a1)
	ld s9, 88(a1)
	ld s10, 96(a1)
	ld s11, 104(a1)

	ret    /* return to ra */

```

就是将当前硬件CPU上面的callee-saved registers读出来saved在当前用户线程的`struct context context`对象里面，将要执行的用户线程的callee-saved registers从`struct context context`对象中取出来加载硬件CPU上。

`thread_create`函数的实现有个坑点：

```c 
void 
thread_create(void (*func)())
{
  struct thread *t;

  for (t = all_thread; t < all_thread + MAX_THREAD; t++) {
    if (t->state == FREE) break;
  }
  t->state = RUNNABLE;
  // YOUR CODE HERE
  // printf("t->state:%d\n", t->state);
  t->context.sp = (uint64)(t->stack) + STACK_SIZE;
  t->context.ra = (uint64)(func);
}
```

* sp是从高地址开始，向低地址蔓延，所以这里`t->context.sp = (uint64)(t->stack) + STACK_SIZE;`，之前直接``t->context.sp = (uint64)(t->stack) `这样使用，而且`all_thread`是个数组结构，所以在运行时候会`踩`到之前的元素的结构体；即`all_thread[2]`线程运行时候的stack会蔓延向`all_thread[1]`的结构体；

* 如何让`all_thread[1]`切换到自己的stack上之后，开始从`thread_a`开始执行，`ret`指令执行之后，程序计数器会读取`ra`寄存器的值，所以这里`t->context.ra = (uint64)(func);`这么写。

## Using threads (moderate)

在本作业中，您将探索使用`hash table`进行lock与线程的并行编程。您应该在具有多个内核的真正的Linux或MacOS计算机（不是xv6，也不是qemu）上执行此任务。大多数最新的笔记本电脑都有多核处理器。

这个作业使用`UNIX pthread`线程库。您可以通过`man pthreads`命令从手册页找到有关它的信息，也可以在web上查找，例如

https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_mutex_lock.html

https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_mutex_init.html

https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_create.html

文件`notxv6/ph.c`包含一个简单的`hash table`，如果从单个线程使用它是正确的，但如果从多个线程使用它就不正确了。在xv6目录（可能是`~/xv6-labs-2020`）中，输入以下内命令：

```bash
$ make ph
$ ./ph 1
```

请注意，要构建`ph`， Makefile使用的是操作系统的gcc，而不是6.S081工具。`ph`的参数指定在`hash table`上执行put和get操作的线程数。运行一段时间后，`ph 1`将产生类似于以下的输出：

```bash
100000 puts, 3.991 seconds, 25056 puts/second
0: 0 keys missing
100000 gets, 3.981 seconds, 25118 gets/second
```

您看到的数字可能与这个示例输出相差两倍或更多，这取决于您的计算机有多快，是否有多个核心，以及它是否忙于做其他事情。

`ph`运行两个基准。首先，它通过调用`put()`将许多`keys`添加到`hash table`中，并以每秒`puts`次数为单位打印实现的速率。它使用`get()`从哈希表中拿走`keys`。它打印由于`put`操作而应该在哈希表中但缺少的数字键（在本例中为零），并打印每秒实现的`get`次数。

通过给`ph`一个大于1的参数，可以告诉它同时从多个线程使用它的哈希表。试试`ph 2`：

```bash
$ ./ph 2
100000 puts, 1.885 seconds, 53044 puts/second
1: 16579 keys missing
0: 16579 keys missing
200000 gets, 4.322 seconds, 46274 gets/second
```

这个`ph 2`输出的第一行表明，当两个线程并发地向哈希表中添加条目时，它们达到了每秒53,044次插入的总速率。这大约是运行`ph 1`时单线程速率的两倍。这是一个出色的“并行加速”，大约是2倍，这是人们可能希望的（即两倍的内核产生两倍的单位时间的工作）。

但是，缺少16579个键的两行表明，大量本应在哈希表中的键不在哈希表中。也就是说，`puts`应该将这些键添加到哈希表中，但是出了问题。看看`notxv6/ph.c`，特别是`put()`和`insert()`。

>为什么有2个线程，而不是1个线程丢失的键？用两个线程确定可能导致丢失密钥的事件序列。在`answers-thread.txt`中提交您的序列并附上简短的解释



>为了避免这种事件序列，请在`notxv6/ph.c`的`put`和`get`中插入`lock`和`unlock`语句，以便在两个线程中丢失的键数始终为0。相关的`pthread`调用是：
>
>```bash
>pthread_mutex_t lock;            // declare a lock
>pthread_mutex_init(&lock, NULL); // initialize the lock
>pthread_mutex_lock(&lock);       // acquire lock
>pthread_mutex_unlock(&lock);     // release lock
>```
>
>当`make grade`表示您的代码通过`ph_safe`测试时，您就完成了，该测试要求两个线程中的零丢失键。此时，`ph_fast`测试失败也没关系。

不要忘记调用`pthread_mutex_init()`。先用一个线程测试你的代码，然后用两个线程测试。测试它是否正确（即你是否消除了丢失的键？）？相对于单线程版本，双线程版本是否实现了并行加速（即每单位时间内完成的总工作量更多）？

在某些情况下，并发`put()s`操作在`hash table`中读取或写入的内存没有重叠，因此不需要锁来相互保护。您可以更改`ph.c`以利用这种情况来获得一些`put()s`的并行加速吗？提示：每个哈希桶加一个锁怎么样？

>修改代码，使一些`put`操作在保持正确性的同时并行运行。当`make grade`表示代码通过了`ph_safe`和`ph_fast`测试时，就完成了。`ph_fast`测试要求两个线程的`puts/second`至少是一个线程的1.25倍。



## Using threads答案

```c
xym@ubuntu:~/xv6-labs-2020$ git diff notxv6/ph.c
diff --git a/notxv6/ph.c b/notxv6/ph.c
index 6df1500..e4c6e81 100644
--- a/notxv6/ph.c
+++ b/notxv6/ph.c
@@ -16,7 +16,7 @@ struct entry {
 struct entry *table[NBUCKET];
 int keys[NKEYS];
 int nthread = 1;
-
+pthread_mutex_t locks[NBUCKET];
 double
 now()
 {
@@ -39,7 +39,7 @@ static
 void put(int key, int value)
 {
   int i = key % NBUCKET;
-
+  pthread_mutex_lock(&(locks[i]));
   // is the key already present?
   struct entry *e = 0;
   for (e = table[i]; e != 0; e = e->next) {
@@ -53,6 +53,7 @@ void put(int key, int value)
     // the new is new.
     insert(key, value, &table[i], table[i]);
   }
+  pthread_mutex_unlock(&(locks[i]));
 }

 static struct entry*
@@ -60,12 +61,12 @@ get(int key)
 {
   int i = key % NBUCKET;

-
+  pthread_mutex_lock(&(locks[i]));
   struct entry *e = 0;
   for (e = table[i]; e != 0; e = e->next) {
     if (e->key == key) break;
   }
-
+  pthread_mutex_unlock(&(locks[i]));
   return e;
 }

@@ -103,12 +104,18 @@ main(int argc, char *argv[])
   void *value;
   double t1, t0;
   if (argc < 2) {
     fprintf(stderr, "Usage: %s nthreads\n", argv[0]);
     exit(-1);
   }
   nthread = atoi(argv[1]);
   tha = malloc(sizeof(pthread_t) * nthread);
+  for(int i = 0; i < NBUCKET; i++){
+    pthread_mutex_init(&(locks[i]), NULL);
+  }
+
   srandom(0);
   assert(NKEYS % nthread == 0);
   for (int i = 0; i < NKEYS; i++) {
```

每个hash bucket一个锁。对于每个桶的put操作，直接加锁给锁上，put之后解锁。对于get操作不用管。本题中是先put再get，对于put与get交织的那种情况，get操作也需要加锁。



## Barrier(moderate)

在本作业中，您将实现一个屏障：应用程序中的一个点，所有参与的线程必须等待，直到所有其他参与的线程也到达该点。您将使用pthread condition variables，这是一种序列协调技术，类似于xv6的sleep和wakeup。

您应该在一台真正的计算机（不是xv6，也不是qemu）上完成这个任务。

文件`notxv6/barrier.c`包含一个`broken barrier`。

```bash
$ make barrier
$ ./barrier 2
barrier: notxv6/barrier.c:42: thread: Assertion `i == t' failed.
```

参数2指定在`barrier`上同步的线程数（`barrier.c`中的`nthread`）。每个线程执行一个循环。在每个循环迭代中，线程调用`barrier()`，然后休眠一个随机的微秒数。assert触发，因为一个线程在另一个线程到达屏障之前离开了屏障。期望的行为是，每个线程都阻塞在`barrier()`中，直到它们的所有n个线程都调用了`barrier()`。

>您的目标是实现期望的障碍行为。除了在`ph`作业中看到的锁的接口之外，还需要以下新的`pthread`原语；具体参考资料如下：
>
>https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_cond_wait.html
>
>https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_cond_broadcast.html
>
>```bash
>pthread_cond_wait(&cond, &mutex);  // go to sleep on cond, releasing lock mutex, acquiring upon wake up
>pthread_cond_broadcast(&cond);     // wake up every thread sleeping on cond
>```
>
>确保你的代码可以通过`make grade`的`barrier`测试

`pthread_cond_wait`在被调用时释放`mutex`，并在返回之前重新获取`mutex`。

我们已经给出了`barrier_init()`。你的工作是实现`barrier()`，这样`panic`就不会发生。我们已经为你们定义了`struct barrier`；它的字段供您使用。

有两个问题会使你的任务复杂化：

* 你必须处理一连串的barrier的调用，每一次调用一轮。`bstate.round`记录当前轮。您应该增加`bstate.round`当每次所有线程都到达障碍。
* 您必须处理这样一种情况：在其他线程退出屏障之前，一个线程在循环中赛跑。特别是，您正在重用bstate.nthread从一轮到下一轮的时候。确保离开屏障并在循环中赛跑的线程不会增加bstate.nthread。当上一轮仍在使用它时。

用一个、两个或两个以上的线程测试代码。

## Barrier答案

```c
xym@ubuntu:~/xv6-labs-2020$ git diff notxv6/barrier.c
diff --git a/notxv6/barrier.c b/notxv6/barrier.c
index 12793e8..91a058c 100644
--- a/notxv6/barrier.c
+++ b/notxv6/barrier.c
@@ -19,7 +19,7 @@ barrier_init(void)
 {
   assert(pthread_mutex_init(&bstate.barrier_mutex, NULL) == 0);
   assert(pthread_cond_init(&bstate.barrier_cond, NULL) == 0);
-  bstate.nthread = 0;
+  bstate.nthread = nthread;
 }

# static void
@@ -30,7 +30,17 @@ barrier()
static void 
barrier()
{
  // YOUR CODE HERE
  //
   // Block until all threads have called barrier() and
   // then increment bstate.round.
   //
-
+  pthread_mutex_lock(&bstate.barrier_mutex);
+  nthread--;
+  if(nthread > 0){
+    pthread_cond_wait(&bstate.barrier_cond, &bstate.barrier_mutex);
+  } else {
+    round++;
+    bstate.round = round;
+    nthread = bstate.nthread;
+    pthread_cond_broadcast(&bstate.barrier_cond);
+  }
+  pthread_mutex_unlock(&bstate.barrier_mutex);
 }

 static void *

```

pthread_cond_wait(&bstate.barrier_cond, &bstate.barrier_mutex);：在被调用时释放`mutex`锁，然后绑定cond陷入sleep，收到wakeup之后并在返回之前重新获取`mutex`锁。

pthread_cond_broadcast(&bstate.barrier_cond)：唤醒所有的绑定cond陷入沉睡的线程。

思路：假设有3个线程，全局变量nthread为3，

1线程最先调用barrier()函数，获取mutex锁，对nthread减一此时nthread变为2；然后wait即释放mutex锁然后wait。

2线程最先调用barrier()函数，获取mutex锁，对nthread减一此时nthread变为1；然后wait即释放mutex锁然后wait。

3线程最先调用barrier()函数，获取mutex锁，对nthread减一此时nthread变为0；对bstate.round = round;进行更新，对nthread=3全局变量进行赋值，调用pthread_mutex_unlock唤醒线程1与线程2；释放mutex锁。退出barrier函数。

线程1与线程2开始争抢mutex锁，假设线程2抢到mutex；线程2释放mutex锁，退出barrier函数。

线程1后抢到mutex；线程1释放mutex锁，退出barrier函数。





## make grade

```bash
make[1]: Leaving directory '/home/xym/xv6-labs-2020'
== Test uthread ==
$ make qemu-gdb
uthread: OK (3.6s)
== Test answers-thread.txt == answers-thread.txt: OK
== Test ph_safe == make[1]: Entering directory '/home/xym/xv6-labs-2020'
make[1]: 'ph' is up to date.
make[1]: Leaving directory '/home/xym/xv6-labs-2020'
ph_safe: OK (10.4s)
== Test ph_fast == make[1]: Entering directory '/home/xym/xv6-labs-2020'
make[1]: 'ph' is up to date.
make[1]: Leaving directory '/home/xym/xv6-labs-2020'
ph_fast: OK (23.0s)
== Test barrier == make[1]: Entering directory '/home/xym/xv6-labs-2020'
make[1]: 'barrier' is up to date.
make[1]: Leaving directory '/home/xym/xv6-labs-2020'
barrier: OK (11.5s)
== Test time ==
time: FAIL
    Cannot read time.txt
Score: 59/60
make: *** [Makefile:317: grade] Error 1

```

