# 自旋锁的实现（二）

[toc]

关于spinlock的实现，有3个细节要讲一下：



首先，有很多同学提问说为什么release函数中不直接使用一个store指令将锁的locked字段写为0？有人想回答一下为什么吗？

> 学生回答：因为其他的处理器可能会向locked字段写入1，或者写入0。

是的，可能有两个处理器或者CPU同时向locked字段写入数据。这里的问题是，对于很多人来说，甚至包括我自己来说，经常会认为一个store指令是一个原子操作，但实际并不总是这样，这取决于具体的实现。

例如，对于CPU缓存cache，每一个cache line的大小可能大于一个整数，那么store指令实际的过程将会是：首先会加载cache line，之后再更新cache line。所以对store指令来说，里面包含了两个微指令。这样的话就有可能得到错误的结果。

所以避免理解硬件的实现细节，我们应该知道，整数操作不是原子的，向一个64bit的内存地址写数据也不是原子的，我们直接使用RISC-V提供的确保原子性的指令来将locked字段写为0。

amoswap指令并不是唯一的原子指令，下图是RISC-V手册中列出来的所有的原子指令：

![img](.assets/image%20(476).png)

第二个细节是，在acquire函数最开始，为啥要关闭中断。让我们回到uart.c文件中，uartputc函数调用acquire函数，此时acquire函数中不关闭中断会怎么样？

![img](.assets/image%20(515).png)

uartputc函数调用acquire函数获取到了锁；此时UART芯片完成了之前的字符传输，是的，会生成一个中断之后运行uartintr函数，uartintr函数中，也会试图acquire同一把锁，但是此时这把锁已经被uartputc持有。那么此时只有一个CPU的话，直接就是deadlock。因为当前CPU持有锁是uartputc的，之后来了个Interrupt当前CPU又开始执行uartintr函数，该函数的第一件事就是试图acquire一个当前CPU已经持有的锁，xv6中对这种情况直接生成一个panic。

所以spinlock需要处理两类并发情况：

* 一类是不同CPU核之间的并发
* 一类是相同CPU核上中断处理程序与普通程序之间的并发。我们需要再acquire中关闭中断，中断会在release执行完成之后打开，之后xv6才可以安全的接收中断并处理中断。

第三个细节是Memory ordering。假设我们先通过将locked设置为1来获取锁，然后再critical section中加x加1，之后通过将locked字段设置为0来释放锁。下面是CPU上执行上述操作的指令流：

![img](.assets/image%20(481).png)

但是编译器或者处理器可能会重排指令以获得更好的性能。对于上面的串行指令流，如果将x<-x+1移到locked<-0之后可以吗？

这是可以的，因为x跟锁目前看是相互独立的，它们之间没有关联。如果他们还是按照串行的方式执行，x<-x+1移到锁之外也没有问题。所以在一个<font color=red>串行执行的场景</font>下是没有问题的。实际中，处理器在执行指令时，实际指令的执行顺序可能会改变。编译器也会做类似的事情，编译器可能会在不改变执行结果的前提下，优化掉一些代码路径并进而改变指令的顺序。

但是在<font color=red>并发执行场景</font>下是完全错误的。如果我们将critical section与加锁解锁放在不同的CPU执行，将会得到完全错误的结果。所以指令重新排序在并发场景是错误的。为了禁止，或者说为了告诉编译器和硬件不要这样做，我们需要使用memory fence或者叫做synchronize指令，来确定指令的移动范围。对于synchronize指令，任何在它之前的load/store指令，都不能移动到它之后。锁的acquire和release函数都包含了synchronize指令。

![img](.assets/image%20(452)%20(1)%20(1)%20(1)%20(1).png)

这样前面的例子中，x=x+1就不会被移动到特定的memory synchronizztion点之外。我们也就不会有memory ordering带来的问题。这就是为什么在acquire和release中都有__sync_synchronize函数的调用。

>学生提问：有没有可能在锁acquire之前的一条指令被移到锁release之后？或者说这里会有一个界限不允许这么做？
>
>教授回答：在这里的例子中，acquire与release都有自己的的界限（注，也就是__sync_synchronize函数的调用点）。所以发生在锁acquire之前的指令不会被移动到acquire的`__sync_synchronize`函数调用之后，这是一个界限。在锁的release函数中还有另一个界限。所以在第一个界限之前的指令会一直在这个界限之前，两个界限之间的指令会保持在两个界限之间，第二个界限之后的指令会保持在第二个界限之后。

****

时间快到了，我来总结一下：

* 首先，锁确保了正确性，但是同时又会降低性能，这是个令人失望的现实，我们是因为并发运行代码才需要使用锁，而锁另一方面又限制了代码的并发运行。

* 锁增加了代码的复杂性，我们的一些实验中有锁，我们需要思考锁为什么在这，它在保护什么？如果你在程序中使用了并发，那么一般都需要使用锁。如果你想避免锁带来的复杂性，可以遵循以下原则：

  * 不到万不得已不要使用共享的数据结构，如果不在多个进程之间使用共享的数据结构，那就没有race condition发生，也就不需要锁，代码也不会变得复杂。
  * 如果使用了共享的数据结构，那么你就需要锁，你可以先从coarse-grained lock大锁开始，然后向fine-grained lock演进
  * 使用race detector来找到race condition，如果你将锁的acquire和release放置于错误的位置，那么就算使用了锁还是会有race。

  以上就是对锁的介绍，我们之后还会介绍很多锁的内容，在这门课程的最后我们还会介绍lock free program，并看一下如何在内核中实现它。

  >学生提问：在一个处理器上运行多个线程与在多个处理器上运行多个进程是否一样？
  >
  >教授回答：差不多吧，如果你有多个线程，但是只有一个CPU，那么你还是会想要特定的内核代码能够原子执行。所以你还是需要critical section的概念。你或许不需要锁，但是你还是需要能够对特定的代码打开或关闭中断。如果你查看一些操作系统的内核代码，通常它们都没有锁的acquire，因为它们都假设自己运行在单个CPU上，但是他们都有开关中断的操作。
  >
  >